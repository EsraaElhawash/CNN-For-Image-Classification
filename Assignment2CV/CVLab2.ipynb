{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CVLab2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nCm8AWkg28v",
        "colab_type": "code",
        "outputId": "19a317f6-7485-422b-c447-94c73b2e5fb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import keras \n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D, SeparableConv2D\n",
        "from keras.regularizers import l2\n",
        "from keras.optimizers import SGD, RMSprop\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.layers import Input, GlobalAveragePooling2D\n",
        "from keras import models\n",
        "from keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "mean = np.mean(x_train)\n",
        "std = np.std(x_train)\n",
        "x_train = (x_train - mean)/(std)\n",
        "x_test = (x_test - mean)/(std)\n",
        "\n",
        "# one hot encode target values\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#FINAL TABLE IMPLEMENTATION!!!!!!!!!!!\n",
        "\n",
        "input_img = Input(shape=(32,32, 3))\n",
        "print(input_img.shape)\n",
        "\n",
        "  #layer0 = Conv2D(8, (3,3),strides=(2,2) ,padding='valid' ,activation='relu')(input_img)\n",
        "  #layer1 = Conv2D(8, (3,3), padding='valid', activation='relu')(input_img)\n",
        "  #layer2 = Conv2D(8, (3,3), padding='same', activation='relu')(layer1)\n",
        "  #layer3 = MaxPooling2D((3,3), strides=(2,2), padding='same')(input_img)\n",
        "  #layer4 = Conv2D(8, (3,3), padding='valid', activation='relu')(layer1)\n",
        "  #layer5 = Conv2D(8, (3,3), strides=(2,2), padding='valid', activation='relu')(input_img)\n",
        "  #layer6 = Conv2D(8, (3,3), padding='valid', activation='relu')(layer2)\n",
        "  #layer7 =Input(shape=(32, 32, 3)) #3 x fig 5\n",
        "  #layer70 = Conv2D(8, (1,1), padding='same', activation='relu')(layer7)\n",
        "  #layer71 = Conv2D(8, (3,3), padding='same', activation='relu')(layer70)\n",
        "  #layer72 = Conv2D(8, (3,3), padding='same', activation='relu')(layer71)\n",
        "  #layer73 = Conv2D(8, (1,1), padding='same', activation='relu')(layer7)\n",
        "  #layer74 = Conv2D(8, (3,3), padding='same', activation='relu')(layer73)\n",
        "  #layer75 = MaxPooling2D((3,3), strides=(1,1), padding='same')(layer7)\n",
        "  #layer76 = Conv2D(8, (1,1), padding='same', activation='relu')(layer75)\n",
        "  #layer77 = Conv2D(8, (1,1), padding='same', activation='relu')(layer7)\n",
        "  #mid_1 = keras.layers.concatenate([layer72, layer74, layer76, layer77])\n",
        "  ##second fig 5\n",
        "  ##layer8 =Input(shape=(32, 32, 3)) #3 x fig 5\n",
        "  #layer80 = Conv2D(8, (1,1), padding='same', activation='relu')(mid_1)\n",
        "  #layer81 = Conv2D(8, (3,3), padding='same', activation='relu')(layer80)\n",
        "  #layer82 = Conv2D(8, (3,3), padding='same', activation='relu')(layer81)\n",
        "  #layer83 = Conv2D(8, (1,1), padding='same', activation='relu')(mid_1)\n",
        "  #layer84 = Conv2D(8, (3,3), padding='same', activation='relu')(layer83)\n",
        "  #layer85 = MaxPooling2D((3,3), strides=(1,1), padding='same')(mid_1)\n",
        "  #layer86 = Conv2D(8, (1,1), padding='same', activation='relu')(layer85)\n",
        "  #layer87 = Conv2D(8, (1,1), padding='same', activation='relu')(mid_1)\n",
        "  #mid_12 = keras.layers.concatenate([layer82, layer84, layer86, layer87])\n",
        "  ##third fig 5\n",
        "  #layer90 = Conv2D(8, (1,1), padding='same', activation='relu')(mid_12)\n",
        "  #layer91 = Conv2D(8, (3,3), padding='same', activation='relu')(layer90)\n",
        "  #layer92 = Conv2D(8, (3,3), padding='same', activation='relu')(layer91)\n",
        "  #layer93 = Conv2D(8, (1,1), padding='same', activation='relu')(mid_12)\n",
        "  #layer94 = Conv2D(8, (3,3), padding='same', activation='relu')(layer93)\n",
        "  #layer95 = MaxPooling2D((3,3), strides=(1,1), padding='same')(mid_12)\n",
        "  #layer96 = Conv2D(8, (1,1), padding='same', activation='relu')(layer95)\n",
        "  #layer97 = Conv2D(8, (1,1), padding='same', activation='relu')(mid_12)\n",
        "  #mid_13 = keras.layers.concatenate([layer92, layer94, layer96, layer97])  \n",
        "\n",
        "\n",
        "######################5 x fig 6\n",
        "\n",
        "layer100 = Conv2D(8, (1,1), padding='same', activation='relu')(input_img) #(mid_13)\n",
        "layer101 = Conv2D(8, (1,3), padding='same', activation='relu')(layer100)\n",
        "layer102 = Conv2D(8, (3,1), padding='same', activation='relu')(layer101)\n",
        "layer103 = Conv2D(8, (1,3), padding='same', activation='relu')(layer102)\n",
        "layer104 = Conv2D(8, (3,1), padding='same', activation='relu')(layer103)\n",
        "\n",
        "### 1st layer\n",
        "layer105 = Conv2D(8, (1,1), padding='same', activation='relu')(input_img) #(mid_13)\n",
        "layer106 = Conv2D(8, (1,3), padding='same', activation='relu')(layer105)\n",
        "layer107 = Conv2D(8, (3,1), padding='same', activation='relu')(layer106)\n",
        "\n",
        "### 2nd layer\n",
        "layer108 = MaxPooling2D((3,3), strides=(1,1), padding='same')(input_img) #(mid_13)\n",
        "layer109 = Conv2D(8, (1,1), padding='same', activation='relu')(layer108)\n",
        "\n",
        "### 3rd layer\n",
        "layer110 = Conv2D(8, (1,1), padding='same', activation='relu')(input_img) #(mid_13)\n",
        "\n",
        "### Concatenate\n",
        "mid_14 = keras.layers.concatenate([layer104, layer107, layer109, layer110])\n",
        "\n",
        "###################Second in Fig 6\n",
        "layer200 = Conv2D(8, (1,1), padding='same', activation='relu')(mid_14)\n",
        "layer201 = Conv2D(8, (1,3), padding='same', activation='relu')(layer200)\n",
        "layer202 = Conv2D(8, (3,1), padding='same', activation='relu')(layer201)\n",
        "layer203 = Conv2D(8, (1,3), padding='same', activation='relu')(layer202)\n",
        "layer204 = Conv2D(8, (3,1), padding='same', activation='relu')(layer203)\n",
        "\n",
        "### 1st layer\n",
        "layer205 = Conv2D(8, (1,1), padding='same', activation='relu')(mid_14)\n",
        "layer206 = Conv2D(8, (1,3), padding='same', activation='relu')(layer205)\n",
        "layer207 = Conv2D(8, (3,1), padding='same', activation='relu')(layer206)\n",
        "\n",
        "### 2nd layer\n",
        "layer208 = MaxPooling2D((3,3), strides=(1,1), padding='same')(mid_14)\n",
        "layer209 = Conv2D(8, (1,1), padding='same', activation='relu')(layer208)\n",
        "\n",
        "### 3rd layer\n",
        "layer210 = Conv2D(8, (1,1), padding='same', activation='relu')(mid_14)\n",
        "\n",
        "### Concatenate\n",
        "mid_15 = keras.layers.concatenate([layer204, layer207, layer209, layer210])\n",
        "\n",
        "########################## Third in Fig 6\n",
        "layer300 = Conv2D(8, (1,1), padding='same', activation='relu')(mid_15)\n",
        "layer301 = Conv2D(8, (1,3), padding='same', activation='relu')(layer300)\n",
        "layer302 = Conv2D(8, (3,1), padding='same', activation='relu')(layer301)\n",
        "layer303 = Conv2D(8, (1,3), padding='same', activation='relu')(layer302)\n",
        "layer304 = Conv2D(8, (3,1), padding='same', activation='relu')(layer303)\n",
        "\n",
        "### 1st layer\n",
        "layer305 = Conv2D(8, (1,1), padding='same', activation='relu')(mid_15)\n",
        "layer306 = Conv2D(8, (1,3), padding='same', activation='relu')(layer305)\n",
        "layer307 = Conv2D(8, (3,1), padding='same', activation='relu')(layer306)\n",
        "\n",
        "### 2nd layer\n",
        "layer308 = MaxPooling2D((3,3), strides=(1,1), padding='same')(mid_15)\n",
        "layer309 = Conv2D(8, (1,1), padding='same', activation='relu')(layer308)\n",
        "\n",
        "### 3rd layer\n",
        "layer310 = Conv2D(8, (1,1), padding='same', activation='relu')(mid_15)\n",
        "\n",
        "### Concatenate\n",
        "mid_16 = keras.layers.concatenate([layer304, layer307, layer309, layer310])\n",
        "\n",
        "#Fourth in Fig 6\n",
        "layer400 = Conv2D(8, (1,1), padding='same', activation='relu')(mid_16)\n",
        "layer401 = Conv2D(8, (1,3), padding='same', activation='relu')(layer400)\n",
        "layer402 = Conv2D(8, (3,1), padding='same', activation='relu')(layer401)\n",
        "layer403 = Conv2D(8, (1,3), padding='same', activation='relu')(layer402)\n",
        "layer404 = Conv2D(8, (3,1), padding='same', activation='relu')(layer403)\n",
        "\n",
        "### 1st layer\n",
        "layer405 = Conv2D(8, (1,1), padding='same', activation='relu')(mid_16)\n",
        "layer406 = Conv2D(8, (1,3), padding='same', activation='relu')(layer405)\n",
        "layer407 = Conv2D(8, (3,1), padding='same', activation='relu')(layer406)\n",
        "\n",
        "### 2nd layer\n",
        "layer408 = MaxPooling2D((3,3), strides=(1,1), padding='same')(mid_16)\n",
        "layer409 = Conv2D(8, (1,1), padding='same', activation='relu')(layer408)\n",
        "\n",
        "### 3rd layer\n",
        "layer410 = Conv2D(8, (1,1), padding='same', activation='relu')(mid_16)\n",
        "\n",
        "### Concatenate\n",
        "mid_17 = keras.layers.concatenate([layer404, layer407, layer409, layer410])\n",
        "\n",
        "################ Fifth in fig 6\n",
        "layer500 = Conv2D(8, (1,1), padding='same', activation='relu')(mid_17)\n",
        "layer501 = Conv2D(8, (1,3), padding='same', activation='relu')(layer500)\n",
        "layer502 = Conv2D(8, (3,1), padding='same', activation='relu')(layer501)\n",
        "layer503 = Conv2D(8, (1,3), padding='same', activation='relu')(layer502)\n",
        "layer504 = Conv2D(8, (3,1), padding='same', activation='relu')(layer503)\n",
        "\n",
        "### 1st layer\n",
        "layer505 = Conv2D(8, (1,1), padding='same', activation='relu')(mid_17)\n",
        "layer506 = Conv2D(8, (1,3), padding='same', activation='relu')(layer505)\n",
        "layer507 = Conv2D(8, (3,1), padding='same', activation='relu')(layer506)\n",
        "\n",
        "### 2nd layer\n",
        "layer508 = MaxPooling2D((3,3), strides=(1,1), padding='same')(mid_17)\n",
        "layer509 = Conv2D(8, (1,1), padding='same', activation='relu')(layer508)\n",
        "\n",
        "### 3rd layer\n",
        "layer510 = Conv2D(8, (1,1), padding='same', activation='relu')(mid_17)\n",
        "\n",
        "### Concatenate\n",
        "mid_18 = keras.layers.concatenate([layer504, layer507, layer509, layer510])\n",
        "\n",
        "\n",
        "########  2 x fig 7\n",
        "\n",
        "## layer 0\n",
        "layer600 = Conv2D(8, (1,1), padding='same', activation='relu')(mid_18)\n",
        "\n",
        "layer601 = Conv2D(8, (1,1), padding='same', activation='relu')(mid_18)\n",
        "\n",
        "### 1st layer\n",
        "layer602 = Conv2D(8, (1,3), padding='same', activation='relu')(layer601)\n",
        "\n",
        "### 2nd layer\n",
        "layer603 = Conv2D(8, (3,1), padding='same', activation='relu')(layer601)\n",
        "\n",
        "layer604 = Conv2D(8, (1,1), padding='same', activation='relu')(mid_18)\n",
        "layer605 = Conv2D(8, (3,3), padding='same', activation='relu')(layer604)\n",
        "\n",
        "### 3rd layer\n",
        "layer606 = Conv2D(8, (1,3), padding='same', activation='relu')(layer605)\n",
        "\n",
        "### 4th layer\n",
        "layer607 = Conv2D(8, (3,1), padding='same', activation='relu')(layer605)\n",
        "\n",
        "### 5th layer\n",
        "layer608 = MaxPooling2D((3,3), strides=(1,1), padding='same')(mid_18)\n",
        "layer609 = Conv2D(8, (1,1), padding='same', activation='relu')(layer608)\n",
        "\n",
        "### Concatenate\n",
        "mid_19 = keras.layers.concatenate([layer600, layer602, layer603, layer606, layer607, layer609])\n",
        "\n",
        "######## Second Fig 7\n",
        "\n",
        "## layer 0\n",
        "layer700 = Conv2D(8, (1,1), padding='same', activation='relu')(mid_19)\n",
        "\n",
        "layer701 = Conv2D(8, (1,1), padding='same', activation='relu')(mid_19)\n",
        "\n",
        "### 1st layer\n",
        "layer702 = Conv2D(8, (1,3), padding='same', activation='relu')(layer701)\n",
        "\n",
        "### 2nd layer\n",
        "layer703 = Conv2D(8, (3,1), padding='same', activation='relu')(layer701)\n",
        "\n",
        "layer704 = Conv2D(8, (1,1), padding='same', activation='relu')(mid_19)\n",
        "layer705 = Conv2D(8, (3,3), padding='same', activation='relu')(layer704)\n",
        "\n",
        "### 3rd layer\n",
        "layer706 = Conv2D(8, (1,3), padding='same', activation='relu')(layer705)\n",
        "\n",
        "### 4th layer\n",
        "layer707 = Conv2D(8, (3,1), padding='same', activation='relu')(layer705)\n",
        "\n",
        "### 5th layer\n",
        "layer708 = MaxPooling2D((3,3), strides=(1,1), padding='same')(mid_19)\n",
        "layer709 = Conv2D(8, (1,1), padding='same', activation='relu')(layer708)\n",
        "\n",
        "### Concatenate\n",
        "mid_20 = keras.layers.concatenate([layer600, layer702, layer703, layer706, layer707, layer709])\n",
        "\n",
        "\n",
        "layerpool =MaxPooling2D((8,8), strides=(1,1), padding='same')(mid_20)\n",
        "flatlayer = Flatten()(layerpool)\n",
        "outputTable = Dense(10, activation='softmax')(flatlayer)\n",
        "print(outputTable.shape)\n",
        "modelTable = Model([input_img], outputTable)\n",
        "\n",
        "\n",
        "modelTable.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = modelTable.fit(x_train, y_train, epochs=10,validation_split=0.1, batch_size=100)\n",
        "\n",
        "plt.title('Accuracy')\n",
        "plt.plot(history.history['acc'], label='test')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "temp,accurate = modelTable.evaluate(x_test, y_test, batch_size = 100)\n",
        "print(accurate)\n",
        "modelTable.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "(?, 32, 32, 3)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "(?, 10)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "45000/45000 [==============================] - 71s 2ms/step - loss: 1.6756 - acc: 0.4097 - val_loss: 1.3847 - val_acc: 0.5010\n",
            "Epoch 2/10\n",
            "45000/45000 [==============================] - 60s 1ms/step - loss: 1.2446 - acc: 0.5589 - val_loss: 1.1435 - val_acc: 0.5912\n",
            "Epoch 3/10\n",
            "45000/45000 [==============================] - 60s 1ms/step - loss: 1.0835 - acc: 0.6176 - val_loss: 1.0638 - val_acc: 0.6292\n",
            "Epoch 4/10\n",
            "45000/45000 [==============================] - 60s 1ms/step - loss: 0.9795 - acc: 0.6564 - val_loss: 0.9719 - val_acc: 0.6636\n",
            "Epoch 5/10\n",
            "45000/45000 [==============================] - 60s 1ms/step - loss: 0.9151 - acc: 0.6787 - val_loss: 0.9321 - val_acc: 0.6822\n",
            "Epoch 6/10\n",
            "45000/45000 [==============================] - 60s 1ms/step - loss: 0.8704 - acc: 0.6949 - val_loss: 0.9049 - val_acc: 0.6934\n",
            "Epoch 7/10\n",
            "45000/45000 [==============================] - 60s 1ms/step - loss: 0.8196 - acc: 0.7123 - val_loss: 0.9042 - val_acc: 0.6874\n",
            "Epoch 8/10\n",
            "45000/45000 [==============================] - 60s 1ms/step - loss: 0.7800 - acc: 0.7258 - val_loss: 0.8700 - val_acc: 0.7040\n",
            "Epoch 9/10\n",
            "45000/45000 [==============================] - 60s 1ms/step - loss: 0.7523 - acc: 0.7343 - val_loss: 0.8756 - val_acc: 0.6968\n",
            "Epoch 10/10\n",
            "45000/45000 [==============================] - 60s 1ms/step - loss: 0.7233 - acc: 0.7454 - val_loss: 0.8774 - val_acc: 0.7044\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXxV9Z3/8dcnIRDWQEhYskCC7Iug\nhEUp7ijaFm2rFq2ttlXaGXU6XWx12mqrM1M7ndr2MWP7q7V2nLoAYsemVatSt1ar5kZBIAiyJ2EL\nBAIEQrbP7497wQsN5gIJ5y7v5+NxH+ac8z33fu71kTfffM/3fo+5OyIikrzSgi5AREQ6l4JeRCTJ\nKehFRJKcgl5EJMkp6EVEkpyCXkQkySnoRUSSnIJekoaZvWxmu8ysW9C1iMQTBb0kBTMrAmYCDsw5\nha/b5VS9lsiJUtBLsvgc8AbwP8D1h3aaWXcz+7GZbTSzOjP7q5l1jxz7iJm9bma7zazSzG6I7H/Z\nzG6Meo4bzOyvUdtuZjeb2fvA+5F9P4s8xx4zKzezmVHt083sX8xsrZntjRwvNLP7zezH0W/CzErN\n7Kud8QFJ6lLQS7L4HPBo5HGJmQ2M7P9PYDJwNpANfBNoNbOhwLPAfwG5wCRgyXG83hXANGBsZLss\n8hzZwGPAE2aWGTn2NeAa4DKgD/AFYD/wMHCNmaUBmFkOcFHkfJEOo6CXhGdmHwGGAgvdvRxYC1wb\nCdAvAF9x92p3b3H31939IHAtsNjdH3f3Jnff6e7HE/Q/cPdadz8A4O6PRJ6j2d1/DHQDRkXa3gh8\nx91XedjSSNu3gDrgwki7ucDL7r7tJD8SkSMo6CUZXA887+47ItuPRfblAJmEg/9ohcfYH6vK6A0z\n+4aZrYwMD+0GsiKv395rPQxcF/n5OuC3J1GTSJt0IUkSWmS8/Wog3cy2RnZ3A/oCg4EG4DRg6VGn\nVgJTj/G09UCPqO1BbbQ5vOxrZDz+m4R75ivcvdXMdgEW9VqnAcvbeJ5HgOVmNhEYAzx1jJpETph6\n9JLorgBaCI+VT4o8xgB/ITxu/xBwn5nlRS6KnhWZfvkocJGZXW1mXcysv5lNijznEuCTZtbDzIYD\nX2ynht5AM1ADdDGzOwmPxR/yIHCPmY2wsNPNrD+Au1cRHt//LfDkoaEgkY6koJdEdz3wG3ff5O5b\nDz2A/wY+A9wOLCMcprXAD4E0d99E+OLo1yP7lwATI8/5E6AR2EZ4aOXRdmp4DvgTsBrYSPiviOih\nnfuAhcDzwB7g10D3qOMPAxPQsI10EtONR0SCZWbnEB7CGer6hZROoB69SIDMLAP4CvCgQl46i4Je\nJCBmNgbYTfii8U8DLkeSmIZuRESSnHr0IiJJLu7m0efk5HhRUVHQZYiIJJTy8vId7p7b1rG4C/qi\noiJCoVDQZYiIJBQz23isYxq6ERFJcgp6EZEkF1PQm9lsM1tlZmvM7PY2jv/EzJZEHqsjizodOtYS\nday0I4sXEZH2tTtGb2bpwP3ALKAKKDOzUnevONTG3b8a1f5W4Iyopzjg7pM4CU1NTVRVVdHQ0HAy\nTxOXMjMzKSgoICMjI+hSRCRJxXIxdiqwxt3XAZjZfOByoOIY7a8B7uqY8sKqqqro3bs3RUVFmFn7\nJyQId2fnzp1UVVVRXFwcdDkikqRiGbrJ58gFmqoi+/5O5K49xcCLUbszzSxkZm+Y2RUnUmRDQwP9\n+/dPqpAHMDP69++flH+piEj86OjplXOBRe7eErVvqLtXm9kw4EUzW+buR9yEwczmAfMAhgwZ0uYT\nJ1vIH5Ks70tE4kcsPfpqwnfIOaQgsq8tc4HHo3e4e3Xkv+uAlzly/P5QmwfcvcTdS3Jz25zvLyKS\nlPY3NlO+sZaHX9/Ao28ecyr8SYmlR18GjDCzYsIBP5fw/TaPYGajgX7A36L29QP2u/vByI2PZwD/\n0RGFn2q7d+/mscce4x//8R+P+9yf/vSnzJs3jx49erTfWESSVt3+JlZsrmP55jpWbN7D8uo61u2o\n59CSY2cO6ctnpg3t8NdtN+jdvdnMbiF8c4V04CF3X2FmdwMhdz80ZXIuMP+opVbHAL80s1bCfz3c\nGz1bJ5Hs3r2bn//85ycc9Nddd52CXiSFbN/TcDjMV2zew/LNdVTt+uAGYnlZmYzNy+LjE/MYn5fF\nuPw+DOqT2Sm1xDRG7+7PAM8cte/Oo7a/18Z5rxO+c07Cu/3221m7di2TJk1i1qxZDBgwgIULF3Lw\n4EE+8YlP8P3vf5/6+nquvvpqqqqqaGlp4bvf/S7btm1j8+bNnH/++eTk5PDSSy8F/VZEpAO5O1W7\nDoR76tV7Ij32PdTsPXi4TXFOTyYWhnvr4/P7MC4vi+yeXU9ZjXG31k17vv+HFVRs3tOhzzk2rw93\nfXzch7a59957Wb58OUuWLOH5559n0aJFvPXWW7g7c+bM4dVXX6Wmpoa8vDyefvppAOrq6sjKyuK+\n++7jpZdeIicnp0PrFpFTq6XVWb+jnhVRQy8rNu+h7kATAOlpxogBvZg5IifcS8/rw9i8PvTODPZ7\nMgkX9PHg+eef5/nnn+eMM8LXlfft28f777/PzJkz+frXv863vvUtPvaxjzFz5syAKxWRE9XY3Mr7\n2/eyIqqXXrF5DweawpMKu3ZJY/Sg3lw2YfDhXvroQb3JzEgPuPK/l3BB317P+1Rwd+644w6+9KUv\n/d2xt99+m2eeeYbvfOc7XHjhhdx5551tPIOIxJMDjS2s3LqHFVHj6au37qOxpRWAnl3TGZvXh09P\nKWRcXh/G52cxfEAvMtITY7mwhAv6oPTu3Zu9e/cCcMkll/Dd736Xz3zmM/Tq1Yvq6moyMjJobm4m\nOzub6667jr59+/Lggw8eca6GbkSC09rqbN3TwPod9azbUc/6mnrW79jH+h31bKrdT2tkGknfHhmM\nz8vi8x8pYlxeFuPz+lDUvydpaYn7nRcFfYz69+/PjBkzGD9+PJdeeinXXnstZ511FgC9evXikUce\nYc2aNdx2222kpaWRkZHBL37xCwDmzZvH7NmzycvL08VYkU62q74xHOQ7PgjydTX1bNhZT0NT6+F2\n3TPSKc7pybj8LOZMzGNcfhbj87PIy8pMui8yxt09Y0tKSvzoG4+sXLmSMWPGBFRR50v29yfS0Q40\ntkSCPBzmHwR7Pbv3Nx1ul55mDMnuQXFOz8OPYTk9GZbbi4F9uiVVoJtZubuXtHVMPXoRiUvNLa1U\n7TrwwVBLVO98S92R60MN6pNJcU5PLpswmGFRoV6Y3SNhxtE7k4JeRALj7mzfe5B1NUcNteyoZ9PO\n/TS3fjDi0CezC8Nye3HWsP7hIM8Nh3lR/5707KYo+zAJ8+m4e1L9mXVIvA2diXSmfQebeWfTLso2\n7CK0oZallbupb/xgDcSuXdIo7t+TkQN6c8m4QZFhlp4U5/SiX4+MpMyAUyEhgj4zM5OdO3cm3VLF\nh9ajz8zsnK89iwRt+54GyjbsomxDLaGNtVRs3kOrQ5rBmMF9+OSZBYwY2OvwUEteVveEnt0SrxIi\n6AsKCqiqqqKmpiboUjrcoTtMiSQ6d2dtTT2hDbXhHvvGWjbu3A9AZkYaZxT245bzh1NSlM0ZQ/oG\n/m3RVJIQQZ+RkaE7MInEmcbmVlZsriO0YRdvbailfOMuausbAcju2ZWSof24btpQSor6MT4/SxdF\nA5QQQS8iwdvb0MTbm3ZHeuy1LKncfXheelH/HlwwegBTivpRUpTNsJyeSTXMmugU9CLSpm17GsJj\n65Ex9pVbPhhfH5eXxTVThzClKJuSof0Y0EnL60rHUNCLSGR8fR9vrQ/PhinbWEtlbXjt9O4Z6Zw5\ntC+3XjCCKUXZTBrSl16azphQ9H9LJAU1NreyrLru8IXT8o217Ip8ozSnV1dKhmZz/VlFTCnKZmxe\nH42vJzgFvUiK2L63gRdXbmfxyu38dU3N4fH14pyezBo7kJKibKYUZVPUv4fG15OMgl4kSbk7723d\ny59XbuOFldtZWrkbgPy+3bm6pJCzT+vP5KHZ5PbuFnCl0tkU9CJJpLG5lTfX7+TPK7fzQsU2qneH\nx9knFvblGxeP5MIxAxk9qLd67ClGQS+S4HbVN/Ly6u0srtjOK6tr2HewmcyMND4yPIdbLxjOBaMH\naFZMilPQiySgdTX7WLxyG4tXbie0oZZWh9ze3fj4xMFcOHogM4bn0L1r/N3SToIRU9Cb2WzgZ0A6\n8KC733vU8Z8A50c2ewAD3L1v5Nj1wHcix/7V3R/uiMJFUklzSyvlG3fx5/e2s7hiG+t21APh9WJu\nPn84F40ZyIT8LK0TI21qN+jNLB24H5gFVAFlZlbq7hWH2rj7V6Pa3wqcEfk5G7gLKAEcKI+cu6tD\n34VIEtrb0MSrq3eweOU2Xlq1nd37m8hIN6YP688NM4q4YPQACvr1CLpMSQCx9OinAmvcfR2Amc0H\nLgcqjtH+GsLhDnAJ8IK710bOfQGYDTx+MkWLJKuqXfv588rtLF65jTfW7aSpxenXI4MLRg3gorED\nmTkiR4uByXGLJejzgcqo7SpgWlsNzWwoUAy8+CHn5rdx3jxgHsCQIUNiKEkkObS2Ou9W17G4YhuL\nV27jva3hG9APy+3JF2YUc+GYgZw5pC9d9IUlOQkdfTF2LrDI3VvabRnF3R8AHoDwPWM7uCaRuHKg\nsYXX1oSHZP783nZq9h4kPc0oGdqPb182hgvHDGBYbq+gy5QkEkvQVwOFUdsFkX1tmQvcfNS55x11\n7suxlyeSHDbt3M8rq7fz8qoa/rpmBwebW+ndrQvnjMpl1piBnDcql749ugZdpiSpWIK+DBhhZsWE\ng3sucO3RjcxsNNAP+FvU7ueAfzezfpHti4E7TqpikQRwoLGFN9bv5JVVNbyyuob1kVkyQ7J7cM3U\nIVw0ZiBTi7Pp2kVDMtL52g16d282s1sIh3Y68JC7rzCzu4GQu5dGms4F5nvUTVDdvdbM7iH8jwXA\n3YcuzIokk0OrP74cCfY319fS2NxKZkYaZw3rz/VnDeXcUQMozukZdKmSgizebk5dUlLioVAo6DJE\n2rW3oYnX1+7kldU1vLKq5vByA8MH9OLckbmcNyqXKUXZZGboi0vS+cys3N1L2jqmb8aKxMjdWbll\nbzjYV28ntGEXza1Or25dmDG8PzefP5xzRuZobrvEHQW9yIfYvb+Rv7y/g1dW1/Dq6hq27z0IwNjB\nfbjpnGGcOzKXM4f001i7xDUFvUiUQ/PawxdRt7OkcjetDlndM5g5IodzR+Zy7shcLRImCUVBLymv\nZu9B/vJ++CLqX97fQW19I2ZwekFfbrlgBOeNymViQV/StY6MJCgFvaSc5pZW3qnczcurwsv6Lq/e\nA4RvoXfeqHCPfeaIXLJ7al67JAcFvaSE7XsaePG9cLD/dc0O9jY0k55mTB7Sj9suGcW5I3MZO7iP\nVn+UpKSgl6TV1NLKS+9tZ0FZJS+t2k6rw+CsTD46YTDnjszl7OE5ZHXXAmGS/BT0knTW76hnQVkl\ni8qr2LHvILm9u/Hlc0/j8kn5jBzYS7fRk5SjoJekcKCxhWeXb2F+WSVvra8lPc04f9QA5k4p5LxR\nuVr9UVKagl4SlruzvHoPC0Kb+P07m9l7sJmi/j345uxRXHlmgaZAikQo6CXh1O1v4qkl1Swoq6Ri\nyx66dUnjsgmD+fSUQqYVZ2toRuQoCnpJCK2tzhvrd7KgrJJnl2+lsbmVcXl9uOfyccyZlK+LqiIf\nQkEvcW3bngYWlVexoKySTbX76Z3ZhU+XFPLpKYWMz88KujyRhKCgl7jT1rTI6cOy+eqsEVw6frBW\ngxQ5Tgp6iRvravaxMFT1d9Miry4ppEjruIucMAW9BOpAYwvPLNvCgtCR0yI/PaWQ8zUtUqRDKOjl\nlDs0LXJ+2SZKl2hapEhnU9DLKXNoWuT8skpWalqkyCmjoJdOpWmRIsFT0EunWVuzj9ueWMrbm3Zr\nWqRIgGIKejObDfwMSAcedPd722hzNfA9wIGl7n5tZH8LsCzSbJO7z+mAuiWOtbY6D722nh89t4rM\njHR+8MkJfOKMfE2LFAlIu0FvZunA/cAsoAooM7NSd6+IajMCuAOY4e67zGxA1FMccPdJHVy3xKmN\nO+u57Yl3eWtDLReOHsAPPjlBF1dFAhZLj34qsMbd1wGY2XzgcqAiqs1NwP3uvgvA3bd3dKES31pb\nnUff3Mi/P/MeXdKMH115OldOLtAFVpE4EEvQ5wOVUdtVwLSj2owEMLPXCA/vfM/d/xQ5lmlmIaAZ\nuNfdnzr6BcxsHjAPYMiQIcf1BiR4lbX7+daT7/L62p3MHJHDDz91Onl9uwddlohEdNTF2C7ACOA8\noAB41cwmuPtuYKi7V5vZMOBFM1vm7mujT3b3B4AHAEpKSryDapJO5u7ML6vkX/8Y/uPuB5+cwNwp\nherFi8SZWIK+GiiM2i6I7ItWBbzp7k3AejNbTTj4y9y9GsDd15nZy8AZwFokoW2pO8C3nlzGq6tr\nOGtYf/7jytMpzO4RdFki0oZYvl9eBowws2Iz6wrMBUqPavMU4d48ZpZDeChnnZn1M7NuUftncOTY\nviQYd2dReRUX/+RVytbX8v0543j0xmkKeZE41m6P3t2bzewW4DnC4+8PufsKM7sbCLl7aeTYxWZW\nAbQAt7n7TjM7G/ilmbUS/kfl3ujZOpJYtu9t4F9+t4zFK7czpagfP7pyohYbE0kA5h5fQ+IlJSUe\nCoWCLkOiuDulSzdzV+kKDjS2cNslo/j8jGLS0zQWLxIvzKzc3UvaOqZvxsqH2rnvIN95ajnPLt/K\npMK+/OdVExk+oFfQZYnIcVDQyzE9u2wL33lqOXsbmvnm7FHMmzlMywaLJCAFvfydXfWN3FW6gtKl\nmxmf34fHrprEqEG9gy5LRE6Qgl6OsLhiG3f83zJ21TfytVkj+YfzTiNDvXiRhKagFwDqDjRx9x8q\nePLtKkYP6s3/fH4K4/K0yqRIMlDQCy+v2s7tTy6jZt9Bbr1gOLdeMIKuXdSLF0kWCvoUtu9gM//2\ndAWPv1XJiAG9+OVnJzOxsG/QZYlIB1PQp6jX1+zgtkXvsqXuAF86dxhfvWik1osXSVIK+hSzv7GZ\ne599j//920aKc3ryxJfPZvLQfkGXJSKdSEGfQt5aX8s3nlhK5a79fGFGMbddMoruXdWLF0l2CvoU\n0NDUwo+eW8VDr62nsF8P5t80nWnD+gddloicIgr6JPf2pl18Y+FS1u2o57PTh3L7paPp2U3/20VS\niX7jk9TB5hZ+8sL7PPDqWgZndefRG6cxY3hO0GWJSAAU9EnoYHML8/63nFdW1zB3SiHf/ugYemdm\nBF2WiAREQZ9kGptbufnRt3lldQ0/+OQErpmqe/CKpDp9/TGJNLW0cuvjb7N45XbuuWK8Ql5EAAV9\n0mhuaeWfFyzhuRXbuOvjY/ns9KFBlyQicUJBnwRaWp1vPLGUp9/dwrcvG8PnZxQHXZKIxBEFfYJr\nbXW+9eS7PLVkM7ddMoqbzhkWdEkiEmcU9AmstdX59lPLWFRexT9fNIKbzx8edEkiEocU9AnK3bmr\ndAWPv1XJzeefxlcuHBF0SSISp2IKejObbWarzGyNmd1+jDZXm1mFma0ws8ei9l9vZu9HHtd3VOGp\nzN25+48V/PaNjXzpnGF84+JRmFnQZYlInGp3Hr2ZpQP3A7OAKqDMzErdvSKqzQjgDmCGu+8yswGR\n/dnAXUAJ4EB55NxdHf9WUoO7c++z7/Gb1zbw+RlF3H7paIW8iHyoWHr0U4E17r7O3RuB+cDlR7W5\nCbj/UIC7+/bI/kuAF9y9NnLsBWB2x5Semu57YTW/fHUd100fwp0fG6uQF5F2xRL0+UBl1HZVZF+0\nkcBIM3vNzN4ws9nHcS5mNs/MQmYWqqmpib36FPOzxe/zXy+uYe6UQu6eM14hLyIx6aiLsV2AEcB5\nwDXAr8ws5nvSufsD7l7i7iW5ubkdVFJyuf+lNfxk8WqunFzAv39iAmlpCnkRiU0sQV8NFEZtF0T2\nRasCSt29yd3XA6sJB38s50o7fvXqOn703Coun5THDz91ukJeRI5LLEFfBowws2Iz6wrMBUqPavMU\n4d48ZpZDeChnHfAccLGZ9TOzfsDFkX0So9+8tp5/e2YlH50wmB9fNZF0hbyIHKd2Z924e7OZ3UI4\noNOBh9x9hZndDYTcvZQPAr0CaAFuc/edAGZ2D+F/LADudvfazngjyei3b2zk+3+o4JJxA/np3El0\nSdfXHkTk+Jm7B13DEUpKSjwUCgVdRuAWlG3iW08u48LRA/jFdZPp2kUhLyLHZmbl7l7S1jGlRxx6\nsryK23+3jHNH5vLz685UyIvISVGCxJnfL6nmtkVLOfu0/vzys5Pp1iU96JJEJMEp6OPI0+9u4WsL\nlzKlKJsHPzeFzAyFvIicPAV9nHhuxVa+Mv8dzijsy0M3TKF7V4W8iHQMBX0cePG9bdzy2NuMz8/i\nN5+fQs9uupWviHQcBX3AXlldw5d/+zajB/Xh4S9MpXdmRtAliUiSUdAH6LU1O5j3vyGGD+jFb784\nlazuCnkR6XgK+oC8sW4nX3y4jKL+PXnkxmn07dE16JJEJEkp6AMQ2lDLF/6njIJ+PXj0pmlk91TI\ni0jnUdCfYu9s2sUNvyljYJ9MHrtxGjm9ugVdkogkOQX9KbSsqo7PPfQW2T278thN0xjQJzPokkQk\nBSjoT5GKzXu47tdvktU9g8fnTWdwVvegSxKRFKGgPwVWbd3Ldb9+kx5d03n8punk91XIi8ipo6Dv\nZGu27+UzD75BlzTj8ZumU5jdI+iSRCTFKOg70bqafVzzqzcB4/F50ynK6Rl0SSKSghT0nWTjznqu\n/dWbtLY6j980jdNyewVdkoikKC2q0gkqa/dz7a/epKG5hcdvms6Igb2DLklEUph69B2str6Rax98\ng70NTTzyxWmMGdwn6JJEJMWpR9/BHn9rE5W1B3jyH85mfH5W0OWIiKhH35HcnSdClUwrzmby0H5B\nlyMiAsQY9GY228xWmdkaM7u9jeM3mFmNmS2JPG6MOtYStb+0I4uPN2+tr2XDzv1cXVIYdCkiIoe1\nO3RjZunA/cAsoAooM7NSd684qukCd7+ljac44O6TTr7U+LcgVEnvbl24bMLgoEsRETkslh79VGCN\nu69z90ZgPnB555aVePY0NPHMsi18fFKebgMoInEllqDPByqjtqsi+472KTN718wWmVn02EWmmYXM\n7A0zu6KtFzCzeZE2oZqamtirjyN/XLqFhqZWDduISNzpqIuxfwCK3P104AXg4ahjQ929BLgW+KmZ\nnXb0ye7+gLuXuHtJbm5uB5V0ai0IVTJqYG8mFmimjYjEl1iCvhqI7qYWRPYd5u473f1gZPNBYHLU\nserIf9cBLwNnnES9cWnV1r0srdzNVSUFmFnQ5YiIHCGWoC8DRphZsZl1BeYCR8yeMbPoq49zgJWR\n/f3MrFvk5xxgBnD0RdyEtzBUSUa68ckzC4IuRUTk77Q768bdm83sFuA5IB14yN1XmNndQMjdS4F/\nMrM5QDNQC9wQOX0M8EszayX8j8q9bczWSWiNza383zvVzBo7ULcEFJG4FNM3Y939GeCZo/bdGfXz\nHcAdbZz3OjDhJGuMa39euY3a+kau0kVYEYlT+mbsSVoQqmRQn0zOGZGYF5FFJPkp6E/ClroDvLq6\nhisnF5CepouwIhKfFPQn4cnyKlodzZ0XkbimoD9Bra3OwlAVZw3rz5D+uj2giMQvBf0JenN9LZtq\n93P1FE2pFJH4pqA/QQtDlfTO7MKl47WAmYjENwX9CTi0gNmciXlkZmgBMxGJbwr6E1C6ZDMHm1v5\n9BRdhBWR+KegPwFPhCoZPag3E3SrQBFJAAr64/Te1j0srarj6pJCLWAmIglBQX+cFpRV0jU9jU+c\n0daS/CIi8UdBfxwONrfwVGQBs35awExEEoSC/jgsrtjOrv1NXK2LsCKSQBT0x2FhqJK8rEw+Mjwn\n6FJERGKmoI/R5t0HePV9LWAmIolHQR+jJ8urcEfrzotIwlHQx6C11VlYXsnZp/WnMFsLmIlIYlHQ\nx+CNdTuprD2gb8KKSEJS0Mfg0AJml4wbFHQpIiLHTUHfjroDTTy7fCtXTMrXAmYikpAU9O0oXaoF\nzEQkscUU9GY228xWmdkaM7u9jeM3mFmNmS2JPG6MOna9mb0feVzfkcWfCgvLKhkzuA/j8voEXYqI\nyAnp0l4DM0sH7gdmAVVAmZmVunvFUU0XuPstR52bDdwFlAAOlEfO3dUh1Xeyis17WFZdx/c+PlYL\nmIlIwoqlRz8VWOPu69y9EZgPXB7j818CvODutZFwfwGYfWKlnnoLQ+EFzC6fpAXMRCRxxRL0+UBl\n1HZVZN/RPmVm75rZIjM7NKAd07lmNs/MQmYWqqmpibH0znWwuYWnllRz8TgtYCYiia2jLsb+AShy\n99MJ99ofPp6T3f0Bdy9x95Lc3NwOKunkvFCxjd37m7ha34QVkQQXS9BXA9FpVxDZd5i773T3g5HN\nB4HJsZ4brxaUVZLft7sWMBORhBdL0JcBI8ys2My6AnOB0ugGZjY4anMOsDLy83PAxWbWz8z6ARdH\n9sW1ql37+euaHVw5uYA0LWAmIgmu3Vk37t5sZrcQDuh04CF3X2FmdwMhdy8F/snM5gDNQC1wQ+Tc\nWjO7h/A/FgB3u3ttJ7yPDvVkefiPjisnFwRciYjIyTN3D7qGI5SUlHgoFArs9VtbnXN+9BJF/Xvy\nyI3TAqtDROR4mFm5u5e0dUzfjD3K39btpGrXAa4qUW9eRJKDgv4oC8oqyeqeoQXMRCRpKOij1O1v\n4k8rtnLFpDwtYCYiSUNBH+X3S6tpbG7VXaREJKko6KMsKKtkXF4fxudnBV2KiEiHUdBHLK+uY8Xm\nPfomrIgkHQV9xBOhSrp2SeMKLWAmIklGQQ80NLXw1JLNzB43iKweGUGXIyLSoRT0wPMV26g7oAXM\nRCQ5KegJ30Uqv293zj6tf9CliIh0uJQP+sra/by2dgdXlWgBMxFJTikf9IvKqwAtYCYiySulg761\n1VlUXsVHhudQ0K9H0OWIiGKPJlAAAAfOSURBVHSKlA7619buoHr3AV2EFZGkltJBvzBURd8eGVw8\nbmDQpYiIdJqUDfrd+xt5bsVWrpiUT7cuWsBMRJJXygb9U++EFzDTsI2IJLuUDfqFoSrG5/dhbF6f\noEsREelUKRn0y6vrqNiyh0+rNy8iKSAlg35hqJJuXdKYowXMRCQFxBT0ZjbbzFaZ2Rozu/1D2n3K\nzNzMSiLbRWZ2wMyWRB7/r6MKP1ENTS089U41s8cPIqu7FjATkeTXpb0GZpYO3A/MAqqAMjMrdfeK\no9r1Br4CvHnUU6x190kdVO9Je27FVvY0NGvYRkRSRiw9+qnAGndf5+6NwHzg8jba3QP8EGjowPo6\n3MJQJYXZ3Zk+TAuYiUhqiCXo84HKqO2qyL7DzOxMoNDdn27j/GIze8fMXjGzmW29gJnNM7OQmYVq\nampirf24Vdbu57U1O7lqcqEWMBORlHHSF2PNLA24D/h6G4e3AEPc/Qzga8BjZvZ38xnd/QF3L3H3\nktzc3JMt6ZieKK/CTAuYiUhqiSXoq4HoAe2CyL5DegPjgZfNbAMwHSg1sxJ3P+juOwHcvRxYC4zs\niMKPV0ursyhUycwRueT17R5ECSIigYgl6MuAEWZWbGZdgblA6aGD7l7n7jnuXuTuRcAbwBx3D5lZ\nbuRiLmY2DBgBrOvwdxGDv67Zwea6Bl2EFZGU0+6sG3dvNrNbgOeAdOAhd19hZncDIXcv/ZDTzwHu\nNrMmoBX4srvXdkThx2thqJJ+PTK4aOyAIF5eRCQw7QY9gLs/Azxz1L47j9H2vKifnwSePIn6OsSu\n+kZeWLGNz0wfogXMRCTlpMQ3Y59aUk1jixYwE5HUlPRB7+4sKKvk9IIsxgzWAmYiknqSPuiXV+/h\nva171ZsXkZSV9EG/ILSJbl3S+PjEvKBLEREJRFIHfUNTC79fspnLJgzWAmYikrKSOuj/tHwrexua\nuapE34QVkdSV1EG/oKySIdk9mF6sBcxEJHUlbdBv2rmfv63bydUlBVrATERSWtIG/RPllaQZfEoL\nmIlIikvKoG9pdRaVV3HOyFwGZ2kBMxFJbUkZ9H95v4YtdQ2aOy8iQpIG/cJQJdk9u3LRmIFBlyIi\nErikC/ra+kZeqNjGJ87Ip2uXpHt7IiLHLemS8P/eqaapxTVsIyISkVRB7+48EapkYmFfRg3qHXQ5\nIiJxIamC/t2qusgCZppSKSJySFIF/YJQJZkZWsBMRCRa0gT9gcYW/rBkM5eNH0yfTC1gJiJySNIE\n/Z6GJs4dlcvcqUOCLkVEJK7EdM/YRDCwTyb/fe2ZQZchIhJ3YurRm9lsM1tlZmvM7PYPafcpM3Mz\nK4nad0fkvFVmdklHFC0iIrFrt0dvZunA/cAsoAooM7NSd684ql1v4CvAm1H7xgJzgXFAHrDYzEa6\ne0vHvQUREfkwsfTopwJr3H2duzcC84HL22h3D/BDoCFq3+XAfHc/6O7rgTWR5xMRkVMklqDPByqj\ntqsi+w4zszOBQnd/+njPFRGRznXSs27MLA24D/j6STzHPDMLmVmopqbmZEsSEZEosQR9NRC9cExB\nZN8hvYHxwMtmtgGYDpRGLsi2dy4A7v6Au5e4e0lubu7xvQMREflQsQR9GTDCzIrNrCvhi6ulhw66\ne52757h7kbsXAW8Ac9w9FGk318y6mVkxMAJ4q8PfhYiIHFO7s27cvdnMbgGeA9KBh9x9hZndDYTc\nvfRDzl1hZguBCqAZuFkzbkRETi1z96BrOIKZ1QAbT+IpcoAdHVROotNncSR9HkfS5/GBZPgshrp7\nm2PfcRf0J8vMQu5e0n7L5KfP4kj6PI6kz+MDyf5ZJM1aNyIi0jYFvYhIkkvGoH8g6ALiiD6LI+nz\nOJI+jw8k9WeRdGP0IiJypGTs0YuISBQFvYhIkkuaoI91zfxUYGaFZvaSmVWY2Qoz+0rQNQXNzNLN\n7B0z+2PQtQTNzPqa2SIze8/MVprZWUHXFCQz+2rk92S5mT1uZplB19TRkiLoo9bMvxQYC1wTWQs/\nVTUDX3f3sYTXHro5xT8PCN8rYWXQRcSJnwF/cvfRwERS+HMxs3zgn4ASdx9P+Nv/c4OtquMlRdAT\n+5r5KcHdt7j725Gf9xL+RU7Z5aHNrAD4KPBg0LUEzcyygHOAXwO4e6O77w62qsB1AbqbWRegB7A5\n4Ho6XLIEvda9PwYzKwLOIOrOXynop8A3gdagC4kDxUAN8JvIUNaDZtYz6KKC4u7VwH8Cm4AtQJ27\nPx9sVR0vWYJe2mBmvYAngX929z1B1xMEM/sYsN3dy4OuJU50Ac4EfuHuZwD1QMpe0zKzfoT/+i8m\nfLvTnmZ2XbBVdbxkCfqY1r1PJWaWQTjkH3X33wVdT4BmAHMi90qYD1xgZo8EW1KgqoAqdz/0F94i\nwsGfqi4C1rt7jbs3Ab8Dzg64pg6XLEH/oWvmpxozM8JjsCvd/b6g6wmSu9/h7gWReyXMBV5096Tr\nscXK3bcClWY2KrLrQsLLiKeqTcB0M+sR+b25kCS8ON3uevSJ4Fhr5gdcVpBmAJ8FlpnZksi+f3H3\nZwKsSeLHrcCjkU7ROuDzAdcTGHd/08wWAW8Tnq32Dkm4HIKWQBARSXLJMnQjIiLHoKAXEUlyCnoR\nkSSnoBcRSXIKehGRJKegFxFJcgp6EZEk9/8BBOLbgUW4y1AAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 4s 396us/step\n",
            "0.6939000004529953\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 8)    32          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 8)    200         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 8)    200         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 8)    32          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 8)    200         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 8)    200         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 3)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 8)    200         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 8)    200         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 8)    32          max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 8)    32          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 32)   0           conv2d_5[0][0]                   \n",
            "                                                                 conv2d_8[0][0]                   \n",
            "                                                                 conv2d_9[0][0]                   \n",
            "                                                                 conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 32, 32, 8)    264         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 32, 32, 8)    200         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 32, 32, 8)    200         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 32, 32, 8)    264         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 32, 32, 8)    200         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 32, 32, 8)    200         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 32)   0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 32, 32, 8)    200         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 32, 32, 8)    200         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 32, 32, 8)    264         max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 32, 32, 8)    264         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 32, 32, 32)   0           conv2d_15[0][0]                  \n",
            "                                                                 conv2d_18[0][0]                  \n",
            "                                                                 conv2d_19[0][0]                  \n",
            "                                                                 conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 32, 32, 8)    264         concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 32, 32, 8)    200         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 32, 32, 8)    200         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 32, 32, 8)    264         concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 32, 32, 8)    200         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 32, 32, 8)    200         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 32)   0           concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 32, 32, 8)    200         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 32, 32, 8)    200         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 32, 32, 8)    264         max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 32, 32, 8)    264         concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 32, 32, 32)   0           conv2d_25[0][0]                  \n",
            "                                                                 conv2d_28[0][0]                  \n",
            "                                                                 conv2d_29[0][0]                  \n",
            "                                                                 conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 32, 32, 8)    264         concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 32, 32, 8)    200         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 32, 32, 8)    200         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 32, 32, 8)    264         concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 32, 32, 8)    200         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 32, 32, 8)    200         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 32, 32, 32)   0           concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 32, 32, 8)    200         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 32, 32, 8)    200         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 32, 32, 8)    264         max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 32, 32, 8)    264         concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 32, 32, 32)   0           conv2d_35[0][0]                  \n",
            "                                                                 conv2d_38[0][0]                  \n",
            "                                                                 conv2d_39[0][0]                  \n",
            "                                                                 conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 32, 32, 8)    264         concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 32, 32, 8)    200         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 32, 32, 8)    200         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 32, 32, 8)    264         concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 32, 32, 8)    200         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 32, 32, 8)    200         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 32, 32, 32)   0           concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 32, 32, 8)    200         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 32, 32, 8)    200         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 32, 32, 8)    264         max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 32, 32, 8)    264         concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 32, 32, 32)   0           conv2d_45[0][0]                  \n",
            "                                                                 conv2d_48[0][0]                  \n",
            "                                                                 conv2d_49[0][0]                  \n",
            "                                                                 conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 32, 32, 8)    264         concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 32, 32, 8)    264         concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 32, 32, 8)    584         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 32, 32, 32)   0           concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 32, 32, 8)    264         concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 32, 32, 8)    200         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 32, 32, 8)    200         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 32, 32, 8)    200         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 32, 32, 8)    200         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 32, 32, 8)    264         max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 32, 32, 48)   0           conv2d_51[0][0]                  \n",
            "                                                                 conv2d_53[0][0]                  \n",
            "                                                                 conv2d_54[0][0]                  \n",
            "                                                                 conv2d_57[0][0]                  \n",
            "                                                                 conv2d_58[0][0]                  \n",
            "                                                                 conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 32, 32, 8)    392         concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 32, 32, 8)    392         concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 32, 32, 8)    584         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 32, 32, 48)   0           concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 32, 32, 8)    200         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 32, 32, 8)    200         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 32, 32, 8)    200         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 32, 32, 8)    200         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 32, 32, 8)    392         max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 32, 32, 48)   0           conv2d_51[0][0]                  \n",
            "                                                                 conv2d_62[0][0]                  \n",
            "                                                                 conv2d_63[0][0]                  \n",
            "                                                                 conv2d_66[0][0]                  \n",
            "                                                                 conv2d_67[0][0]                  \n",
            "                                                                 conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2D)  (None, 32, 32, 48)   0           concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 49152)        0           max_pooling2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           491530      flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 506,882\n",
            "Trainable params: 506,882\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42IP7Anm_cph",
        "colab_type": "text"
      },
      "source": [
        "GoogleNet\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyZ0jv8t_erw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_img = Input(shape=(32, 32, 3))\n",
        "\n",
        "conv1 = Conv2D(16, (7,7), padding='same', strides=(2,2), activation='relu')(input_img)\n",
        "maxpool1 = MaxPooling2D((3,3), strides=(2,2), padding='valid')(conv1)\n",
        "norm1 = tf.nn.lrn(maxpool1)\n",
        "conv2 = Conv2D(16, (1,1), padding='same', strides=(1,1), activation='relu')(norm1)\n",
        "conv3 = Conv2D(16, (3,3), padding='same', strides=(1,1), activation='relu')(conv2)\n",
        "norm2 = tf.nn.lrn(conv3)\n",
        "maxpool2 = MaxPooling2D((3,3), strides=(2,2), padding='valid')(norm2)\n",
        "dimRed1 = dimension_reductions(maxpool2)\n",
        "dimRed2 = dimension_reductions(dimRed1)\n",
        "maxpool3 = MaxPooling2D((3,3), strides=(2,2), padding='valid')(dimRed2)\n",
        "dimRed3 = dimension_reductions(maxpool3)\n",
        "\n",
        "# First auxiliary output\n",
        "avg1 = AveragePooling2D(pool_size=(5,5), strides=(3,3))(dimRed3)\n",
        "conv4 = Conv2D(16, (1,1), padding='same', activation='relu')(avg1)\n",
        "flat1 = Flatten()(conv4)\n",
        "dense1 = Dense(1024, activation='relu')(flat1)\n",
        "drop1 = Dropout(0.5)(dense1)\n",
        "dense2 = Dense(1000, activation='relu')(drop1)\n",
        "loss1 = Dense(10, activation='softmax')(dense2)\n",
        "\n",
        "dimRed4 = dimension_reductions(dimRed3)\n",
        "dimRed5 = dimension_reductions(dimRed4)\n",
        "dimRed6 = dimension_reductions(dimRed5)\n",
        "\n",
        "# Second auxiliary output\n",
        "avg2 = AveragePooling2D(pool_size=(5,5), strides=(3,3))(dimRed6)\n",
        "conv5 = Conv2D(16, (1,1), padding='same', activation='relu')(avg2)\n",
        "flat2 = Flatten()(conv5)\n",
        "dense3 = Dense(1024, activation='relu')(flat2)\n",
        "drop2 = Dropout(0.5)(dense3)\n",
        "dense4 = Dense(1000, activation='relu')(drop2)\n",
        "loss2 = Dense(10, activation='softmax')(dense4)\n",
        "\n",
        "dimRed7 = dimension_reductions(dimRed6)\n",
        "maxpool4 = MaxPooling2D((3,3), strides=(2,2), padding='valid')(dimRed7)\n",
        "dimRed8 = dimension_reductions(maxpool4)\n",
        "dimRed9 = dimension_reductions(dimRed8)\n",
        "\n",
        "avg3 = AveragePooling2D(pool_size=(7,7), strides=(1,1))(dimRed9)\n",
        "flat3 = Flatten()(avg3)\n",
        "\n",
        "dense5 = Dense(1200, activation='relu')(flat3)\n",
        "drop3 = Dropout(0.5)(dense5)\n",
        "dense6 = Dense(600, activation='relu')(drop3)\n",
        "dense7 = Dense(150, activation='relu')(dense6)\n",
        "\n",
        "output = Dense(10, activation='softmax')(dense7)\n",
        "model = Model([input_img], outputs=[loss1, loss2, output])\n",
        "start = time.time()\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'], loss_weights=[0.3,0.3,1])\n",
        "\n",
        "history = model.fit(x_train, [y_train,y_train,y_train], epochs=10, batch_size=100, shuffle=True)\n",
        "end = time.time()\n",
        "print()\n",
        "print(end - start)\n",
        "\n",
        "score = model.evaluate(x_test, [y_test,y_test,y_test], verbose=1)\n",
        "print('Train loss:',score[0])\n",
        "print('Train accuracy:',score[1])\n",
        "\n",
        "# Show accuracy curves    \n",
        "plt.figure()\n",
        "plt.grid()                                              \n",
        "                                                            \n",
        "plt.title('Training performance')                          \n",
        "plt.plot(history.epoch, history.history['loss'], label='train loss+error')  \n",
        "plt.plot(history.epoch, label='val_error')   \n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91jQZlT1_z5-",
        "colab_type": "text"
      },
      "source": [
        "Here the implementations of all 3 figures in paper\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PpazXu9bz1s",
        "colab_type": "code",
        "outputId": "2388ab4a-50c8-40b8-d428-f71fcdeb086b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "#Here are the implementation of the 3 figures separately \n",
        "\n",
        "\n",
        "### FIGURE 5 MODEL\n",
        "input_img = Input(shape=(32, 32, 3))\n",
        "print(input_img.shape)\n",
        "\n",
        "## layer 0\n",
        "layer_0 = Conv2D(8, (1,1), padding='same', activation='relu')(input_img)\n",
        "layer1 = Conv2D(8, (3,3), padding='same', activation='relu')(layer_0)\n",
        "layer2 = Conv2D(8, (3,3), padding='same', activation='relu')(layer1)\n",
        "\n",
        "### 1st layer\n",
        "layer3 = Conv2D(8, (1,1), padding='same', activation='relu')(input_img)\n",
        "layer4 = Conv2D(8, (3,3), padding='same', activation='relu')(layer3)\n",
        "### 2nd layer\n",
        "layer5 = MaxPooling2D((3,3), strides=(1,1), padding='same')(input_img)\n",
        "layer6 = Conv2D(8, (1,1), padding='same', activation='relu')(layer5)\n",
        "####\n",
        "layer7 = Conv2D(8, (1,1), padding='same', activation='relu')(input_img)\n",
        "\n",
        "mid_1 = keras.layers.concatenate([layer2, layer4, layer6, layer7])\n",
        "print(mid_1.shape)\n",
        "\n",
        "flat_1 = Flatten()(mid_1)\n",
        "print(flat_1)\n",
        "dense_1 = Dense(1200, activation='relu')(flat_1)\n",
        "dense_1 = Dropout(0.5)(dense_1)\n",
        "print(dense_1.shape)\n",
        "dense_2 = Dense(600, activation='relu')(dense_1)\n",
        "dense_2 = Dropout(0.5)(dense_2)\n",
        "print(dense_2.shape)\n",
        "dense_3 = Dense(150, activation='relu')(dense_2)\n",
        "print(dense_3.shape)\n",
        "\n",
        "output5 = Dense(10, activation='softmax')(dense_3)\n",
        "#print(output.shape)\n",
        "\n",
        "model5 = Model([input_img], output5)\n",
        "#####FIGURE 6 MODEL\n",
        "\n",
        "input_img = Input(shape=(32, 32, 3))\n",
        "print(input_img.shape)\n",
        "\n",
        "## layer 0\n",
        "layer0 = Conv2D(8, (1,1), padding='same', activation='relu')(input_img)\n",
        "layer1 = Conv2D(8, (1,7), padding='same', activation='relu')(layer0)\n",
        "layer2 = Conv2D(8, (7,1), padding='same', activation='relu')(layer1)\n",
        "layer3 = Conv2D(8, (1,7), padding='same', activation='relu')(layer2)\n",
        "layer4 = Conv2D(8, (7,1), padding='same', activation='relu')(layer3)\n",
        "\n",
        "### 1st layer\n",
        "layer5 = Conv2D(8, (1,1), padding='same', activation='relu')(input_img)\n",
        "layer6 = Conv2D(8, (1,7), padding='same', activation='relu')(layer5)\n",
        "layer7 = Conv2D(8, (7,1), padding='same', activation='relu')(layer6)\n",
        "\n",
        "### 2nd layer\n",
        "layer8 = MaxPooling2D((3,3), strides=(1,1), padding='same')(input_img)\n",
        "layer9 = Conv2D(8, (1,1), padding='same', activation='relu')(layer8)\n",
        "\n",
        "### 3rd layer\n",
        "layer10 = Conv2D(8, (1,1), padding='same', activation='relu')(input_img)\n",
        "\n",
        "### Concatenate\n",
        "mid_1 = keras.layers.concatenate([layer4, layer7, layer9, layer10])\n",
        "print(mid_1.shape)\n",
        "\n",
        "flat_1 = Flatten()(mid_1)\n",
        "print(flat_1)\n",
        "dense_1 = Dense(1200, activation='relu')(flat_1)\n",
        "dense_1 = Dropout(0.5)(dense_1)\n",
        "print(dense_1.shape)\n",
        "dense_2 = Dense(600, activation='relu')(dense_1)\n",
        "dense_2 = Dropout(0.5)(dense_2)\n",
        "print(dense_2.shape)\n",
        "dense_3 = Dense(150, activation='relu')(dense_2)\n",
        "print(dense_3.shape)\n",
        "\n",
        "output6 = Dense(10, activation='softmax')(dense_3)\n",
        "#print(output.shape)\n",
        "\n",
        "model6 = Model([input_img], output6)\n",
        "\n",
        "#FIGURE 7 MODEL\n",
        "input_img = Input(shape=(32, 32, 3))\n",
        "print(input_img.shape)\n",
        "\n",
        "## layer 0\n",
        "layer_0 = Conv2D(8, (1,1), padding='same', activation='relu')(input_img)\n",
        "\n",
        "layer1 = Conv2D(8, (1,1), padding='same', activation='relu')(input_img)\n",
        "\n",
        "### 1st layer\n",
        "layer_1 = Conv2D(8, (1,3), padding='same', activation='relu')(layer1)\n",
        "\n",
        "### 2nd layer\n",
        "layer_2 = Conv2D(8, (3,1), padding='same', activation='relu')(layer1)\n",
        "\n",
        "layer2 = Conv2D(8, (1,1), padding='same', activation='relu')(input_img)\n",
        "layer3 = Conv2D(8, (3,3), padding='same', activation='relu')(layer2)\n",
        "\n",
        "### 3rd layer\n",
        "layer_3 = Conv2D(8, (1,3), padding='same', activation='relu')(layer3)\n",
        "\n",
        "### 4th layer\n",
        "layer_4 = Conv2D(8, (3,1), padding='same', activation='relu')(layer3)\n",
        "\n",
        "### 5th layer\n",
        "layer5 = MaxPooling2D((3,3), strides=(1,1), padding='same')(input_img)\n",
        "layer_5 = Conv2D(8, (1,1), padding='same', activation='relu')(layer5)\n",
        "\n",
        "### Concatenate\n",
        "mid_1 = keras.layers.concatenate([layer_0, layer_1, layer_2, layer_3, layer_4, layer_5])\n",
        "print(mid_1.shape)\n",
        "\n",
        "flat_1 = Flatten()(mid_1)\n",
        "print(flat_1)\n",
        "dense_1 = Dense(1200, activation='relu')(flat_1)\n",
        "dense_1 = Dropout(0.5)(dense_1)\n",
        "print(dense_1.shape)\n",
        "dense_2 = Dense(600, activation='relu')(dense_1)\n",
        "dense_2 = Dropout(0.5)(dense_2)\n",
        "print(dense_2.shape)\n",
        "dense_3 = Dense(150, activation='relu')(dense_2)\n",
        "print(dense_3.shape)\n",
        "\n",
        "output7 = Dense(10, activation='softmax')(dense_3)\n",
        "#print(output.shape)\n",
        "\n",
        "model7 = Model([input_img], output7)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 32, 32, 3)\n",
            "(?, 32, 32, 32)\n",
            "Tensor(\"flatten_8/Reshape:0\", shape=(?, ?), dtype=float32)\n",
            "(?, 1200)\n",
            "(?, 600)\n",
            "(?, 150)\n",
            "(?, 32, 32, 3)\n",
            "(?, 32, 32, 32)\n",
            "Tensor(\"flatten_9/Reshape:0\", shape=(?, ?), dtype=float32)\n",
            "(?, 1200)\n",
            "(?, 600)\n",
            "(?, 150)\n",
            "(?, 32, 32, 3)\n",
            "(?, 32, 32, 48)\n",
            "Tensor(\"flatten_10/Reshape:0\", shape=(?, ?), dtype=float32)\n",
            "(?, 1200)\n",
            "(?, 600)\n",
            "(?, 150)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pp-BKYpkp3XC",
        "colab_type": "text"
      },
      "source": [
        "Epoch 1/10\n",
        "50000/50000 [==============================] - 60s 1ms/step - loss: 2.2902 - acc: 0.3441\n",
        "Epoch 2/10\n",
        "50000/50000 [==============================] - 57s 1ms/step - loss: 1.4176 - acc: 0.4864\n",
        "Epoch 3/10\n",
        "50000/50000 [==============================] - 58s 1ms/step - loss: 1.2345 - acc: 0.5550\n",
        "Epoch 4/10\n",
        "50000/50000 [==============================] - 57s 1ms/step - loss: 1.0793 - acc: 0.6135\n",
        "Epoch 5/10\n",
        "50000/50000 [==============================] - 58s 1ms/step - loss: 0.9333 - acc: 0.6663\n",
        "Epoch 6/10\n",
        "50000/50000 [==============================] - 58s 1ms/step - loss: 0.7905 - acc: 0.7187\n",
        "Epoch 7/10\n",
        "50000/50000 [==============================] - 57s 1ms/step - loss: 0.6663 - acc: 0.7638\n",
        "Epoch 8/10\n",
        "50000/50000 [==============================] - 58s 1ms/step - loss: 0.5410 - acc: 0.8091\n",
        "Epoch 9/10\n",
        "50000/50000 [==============================] - 57s 1ms/step - loss: 0.4504 - acc: 0.8419\n",
        "Epoch 10/10\n",
        "50000/50000 [==============================] - 57s 1ms/step - loss: 0.3674 - acc: 0.8712\n",
        "\n",
        "10000/10000 [==============================] - 2s 199us/step\n",
        "0.6488000005483627\n",
        "Model: \"model_3\"\n",
        "__________________________________________________________________________________________________\n",
        "Layer (type)                    Output Shape         Param #     Connected to                     \n",
        "==================================================================================================\n",
        "input_3 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
        "__________________________________________________________________________________________________\n",
        "conv2d_23 (Conv2D)              (None, 32, 32, 8)    32          input_3[0][0]                    \n",
        "__________________________________________________________________________________________________\n",
        "conv2d_20 (Conv2D)              (None, 32, 32, 8)    32          input_3[0][0]                    \n",
        "__________________________________________________________________________________________________\n",
        "conv2d_24 (Conv2D)              (None, 32, 32, 8)    584         conv2d_23[0][0]                  \n",
        "__________________________________________________________________________________________________\n",
        "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 3)    0           input_3[0][0]                    \n",
        "__________________________________________________________________________________________________\n",
        "conv2d_19 (Conv2D)              (None, 32, 32, 8)    32          input_3[0][0]                    \n",
        "__________________________________________________________________________________________________\n",
        "conv2d_21 (Conv2D)              (None, 32, 32, 8)    200         conv2d_20[0][0]                  \n",
        "__________________________________________________________________________________________________\n",
        "conv2d_22 (Conv2D)              (None, 32, 32, 8)    200         conv2d_20[0][0]                  \n",
        "__________________________________________________________________________________________________\n",
        "conv2d_25 (Conv2D)              (None, 32, 32, 8)    200         conv2d_24[0][0]                  \n",
        "__________________________________________________________________________________________________\n",
        "conv2d_26 (Conv2D)              (None, 32, 32, 8)    200         conv2d_24[0][0]                  \n",
        "__________________________________________________________________________________________________\n",
        "conv2d_27 (Conv2D)              (None, 32, 32, 8)    32          max_pooling2d_3[0][0]            \n",
        "__________________________________________________________________________________________________\n",
        "concatenate_3 (Concatenate)     (None, 32, 32, 48)   0           conv2d_19[0][0]                  \n",
        "                                                                 conv2d_21[0][0]                  \n",
        "                                                                 conv2d_22[0][0]                  \n",
        "                                                                 conv2d_25[0][0]                  \n",
        "                                                                 conv2d_26[0][0]                  \n",
        "                                                                 conv2d_27[0][0]                  \n",
        "__________________________________________________________________________________________________\n",
        "flatten_3 (Flatten)             (None, 49152)        0           concatenate_3[0][0]              \n",
        "__________________________________________________________________________________________________\n",
        "dense_9 (Dense)                 (None, 1200)         58983600    flatten_3[0][0]                  \n",
        "__________________________________________________________________________________________________\n",
        "dropout_5 (Dropout)             (None, 1200)         0           dense_9[0][0]                    \n",
        "__________________________________________________________________________________________________\n",
        "dense_10 (Dense)                (None, 600)          720600      dropout_5[0][0]                  \n",
        "__________________________________________________________________________________________________\n",
        "dense_11 (Dense)                (None, 150)          90150       dense_10[0][0]                   \n",
        "__________________________________________________________________________________________________\n",
        "dense_12 (Dense)                (None, 10)           1510        dense_11[0][0]                   \n",
        "==================================================================================================\n",
        "Total params: 59,797,372\n",
        "Trainable params: 59,797,372\n",
        "Non-trainable params: 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cfjcpn-VnLU",
        "colab_type": "text"
      },
      "source": [
        "50000/50000 [==============================] - 65s 1ms/step - loss: 2.1029 - acc: 0.3173\n",
        "Epoch 2/10\n",
        "50000/50000 [==============================] - 57s 1ms/step - loss: 1.4739 - acc: 0.4675\n",
        "Epoch 3/10\n",
        "50000/50000 [==============================] - 57s 1ms/step - loss: 1.2524 - acc: 0.5530\n",
        "Epoch 4/10\n",
        "50000/50000 [==============================] - 57s 1ms/step - loss: 1.0860 - acc: 0.6155\n",
        "Epoch 5/10\n",
        "50000/50000 [==============================] - 57s 1ms/step - loss: 0.9425 - acc: 0.6678\n",
        "Epoch 6/10\n",
        "50000/50000 [==============================] - 57s 1ms/step - loss: 0.8104 - acc: 0.7141\n",
        "Epoch 7/10\n",
        "50000/50000 [==============================] - 57s 1ms/step - loss: 0.6994 - acc: 0.7523\n",
        "Epoch 8/10\n",
        "50000/50000 [==============================] - 57s 1ms/step - loss: 0.6010 - acc: 0.7882\n",
        "Epoch 9/10\n",
        "50000/50000 [==============================] - 57s 1ms/step - loss: 0.5267 - acc: 0.8156\n",
        "Epoch 10/10\n",
        "50000/50000 [==============================] - 57s 1ms/step - loss: 0.4643 - acc: 0.8371\n",
        "\n",
        "10000/10000 [==============================] - 2s 186us/step\n",
        "0.6577999997138977\n",
        "Model: \"model_1\"\n",
        "__________________________________________________________________________________________________\n",
        "Layer (type)                    Output Shape         Param #     Connected to                     \n",
        "==================================================================================================\n",
        "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
        "__________________________________________________________________________________________________\n",
        "conv2d_5 (Conv2D)               (None, 32, 32, 8)    32          input_1[0][0]                    \n",
        "__________________________________________________________________________________________________\n",
        "conv2d_2 (Conv2D)               (None, 32, 32, 8)    32          input_1[0][0]                    \n",
        "__________________________________________________________________________________________________\n",
        "conv2d_6 (Conv2D)               (None, 32, 32, 8)    584         conv2d_5[0][0]                   \n",
        "__________________________________________________________________________________________________\n",
        "max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 3)    0           input_1[0][0]                    \n",
        "__________________________________________________________________________________________________\n",
        "conv2d_1 (Conv2D)               (None, 32, 32, 8)    32          input_1[0][0]                    \n",
        "__________________________________________________________________________________________________\n",
        "conv2d_3 (Conv2D)               (None, 32, 32, 8)    200         conv2d_2[0][0]                   \n",
        "__________________________________________________________________________________________________\n",
        "conv2d_4 (Conv2D)               (None, 32, 32, 8)    200         conv2d_2[0][0]                   \n",
        "__________________________________________________________________________________________________\n",
        "conv2d_7 (Conv2D)               (None, 32, 32, 8)    200         conv2d_6[0][0]                   \n",
        "__________________________________________________________________________________________________\n",
        "conv2d_8 (Conv2D)               (None, 32, 32, 8)    200         conv2d_6[0][0]                   \n",
        "__________________________________________________________________________________________________\n",
        "conv2d_9 (Conv2D)               (None, 32, 32, 8)    32          max_pooling2d_1[0][0]            \n",
        "__________________________________________________________________________________________________\n",
        "concatenate_1 (Concatenate)     (None, 32, 32, 48)   0           conv2d_1[0][0]                   \n",
        "                                                                 conv2d_3[0][0]                   \n",
        "                                                                 conv2d_4[0][0]                   \n",
        "                                                                 conv2d_7[0][0]                   \n",
        "                                                                 conv2d_8[0][0]                   \n",
        "                                                                 conv2d_9[0][0]                   \n",
        "__________________________________________________________________________________________________\n",
        "flatten_1 (Flatten)             (None, 49152)        0           concatenate_1[0][0]              \n",
        "__________________________________________________________________________________________________\n",
        "dense_1 (Dense)                 (None, 1200)         58983600    flatten_1[0][0]                  \n",
        "__________________________________________________________________________________________________\n",
        "dropout_1 (Dropout)             (None, 1200)         0           dense_1[0][0]                    \n",
        "__________________________________________________________________________________________________\n",
        "dense_2 (Dense)                 (None, 600)          720600      dropout_1[0][0]                  \n",
        "__________________________________________________________________________________________________\n",
        "dropout_2 (Dropout)             (None, 600)          0           dense_2[0][0]                    \n",
        "__________________________________________________________________________________________________\n",
        "dense_3 (Dense)                 (None, 150)          90150       dropout_2[0][0]                  \n",
        "__________________________________________________________________________________________________\n",
        "dense_4 (Dense)                 (None, 10)           1510        dense_3[0][0]                    \n",
        "==================================================================================================\n",
        "Total params: 59,797,372\n",
        "Trainable params: 59,797,372\n",
        "Non-trainable params: 0\n",
        "# __________________________________________________________________________________________________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jNbj1nzs73k",
        "colab_type": "text"
      },
      "source": [
        "Epoch 1/7\n",
        "50000/50000 [==============================] - 59s 1ms/step - loss: 5.5038 - acc: 0.3400\n",
        "Epoch 2/7\n",
        "50000/50000 [==============================] - 57s 1ms/step - loss: 1.1891 - acc: 0.5737\n",
        "Epoch 3/7\n",
        "50000/50000 [==============================] - 57s 1ms/step - loss: 0.9268 - acc: 0.6724\n",
        "Epoch 4/7\n",
        "50000/50000 [==============================] - 57s 1ms/step - loss: 0.6892 - acc: 0.7567\n",
        "Epoch 5/7\n",
        "50000/50000 [==============================] - 57s 1ms/step - loss: 0.4671 - acc: 0.8358\n",
        "Epoch 6/7\n",
        "50000/50000 [==============================] - 57s 1ms/step - loss: 0.2840 - acc: 0.9012\n",
        "Epoch 7/7\n",
        "50000/50000 [==============================] - 57s 1ms/step - loss: 0.1801 - acc: 0.9377\n",
        "\n",
        "Time: 401s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IedTEkCmqT0P",
        "colab_type": "text"
      },
      "source": [
        "Epoch 1/10\n",
        "50000/50000 [==============================] - 59s 1ms/step - loss: 5.9663 - acc: 0.3155\n",
        "Epoch 2/10\n",
        "50000/50000 [==============================] - 57s 1ms/step - loss: 1.2368 - acc: 0.5598\n",
        "Epoch 3/10\n",
        "50000/50000 [==============================] - 57s 1ms/step - loss: 0.9835 - acc: 0.6515\n",
        "Epoch 4/10\n",
        "50000/50000 [==============================] - 57s 1ms/step - loss: 0.7412 - acc: 0.7405\n",
        "Epoch 5/10\n",
        "50000/50000 [==============================] - 57s 1ms/step - loss: 0.4597 - acc: 0.8411\n",
        "Epoch 6/10\n",
        "50000/50000 [==============================] - 57s 1ms/step - loss: 0.2380 - acc: 0.9194\n",
        "Epoch 7/10\n",
        "50000/50000 [==============================] - 57s 1ms/step - loss: 0.1295 - acc: 0.9564\n",
        "Epoch 8/10\n",
        "50000/50000 [==============================] - 57s 1ms/step - loss: 0.0880 - acc: 0.9710\n",
        "Epoch 9/10\n",
        "50000/50000 [==============================] - 57s 1ms/step - loss: 0.0730 - acc: 0.9765\n",
        "Epoch 10/10\n",
        "50000/50000 [==============================] - 57s 1ms/step - loss: 0.0665 - acc: 0.9785\n",
        "\n",
        "\n",
        "Time: 572s"
      ]
    }
  ]
}